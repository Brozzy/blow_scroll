<!doctype html>

<html lang="sl">
<head>
	<meta charset="utf-8">
	<title> Audio API </title>
	  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js" type="text/javascript"></script>

	
</head>

<body>
	<canvas id="canvas" width="512" height="256" ></canvas>
	
	<!-- ----------------------------------------------------- -->
 
		<style>
		#canvas {
		margin-left: auto;
		margin-right: auto;
		display: block;
		background-color: black;
		margin-top:50px;
		}
		#controls {
		text-align: center;
		}
		#start_button, #stop_button {
		font-size: 16pt;
		}
		</style>
 
<!-- ----------------------------------------------------- -->
	<script>
	
	var audioContext;
	var audioBuffer;
	var sourceNode;
	var analyserNode;
	var javascriptNode;
	var audioData = null;
	var audioPlaying = false;
	var sampleSize = 1024; // number of samples to collect before analyzing data
	var amplitudeArray; // array to hold time domain data
	 
	
	// Global Variables for the Graphics
	var canvasWidth = 512;
	var canvasHeight = 256;
	var ctx;



	// Hacks to deal with different function names in different browsers
		window.requestAnimFrame = (function(){
			return window.requestAnimationFrame ||
				window.webkitRequestAnimationFrame ||
				window.mozRequestAnimationFrame ||
				function(callback, element){
				window.setTimeout(callback, 1000 / 60);
				};
		})();

		
		//Create audioContext
		window.AudioContext = window.AudioContext ||
							window.webkitAudioContext ||
							window.mozAudioContext ||
							window.oAudioContext ||	
							window.msAudioContext;
		
		var audioContext = new AudioContext();
		
		//On load call getUserMedia function
		window.onload = getUserMedia({audio:true}, goStream);
		
		//getUserMedia function --> permission to use a media device (microphone)
		
		function getUserMedia(dictionary, callback){
			try{
				navigator.getUserMedia = navigator.getUserMedia ||
										navigator.webkitGetUserMedia ||
										navigator.mozGetUserMedia;
				
				navigator.getUserMedia(dictionary, callback, error);						
			}
			catch(e){
				alert('getUserMedia threw exception :' + e);
			}
		}
		
		//get canvas content --> for visual representation 
		ctx = $("#canvas").get()[0].getContext("2d");

		//main function --> create nodes, array for storing data and connect nodes
		function goStream(stream){
			// create the media stream from the audio input source (microphone)
			sourceNode = audioContext.createMediaStreamSource(stream);
			audioStream = stream;

			analyserNode   = audioContext.createAnalyser();
			javascriptNode = audioContext.createScriptProcessor(sampleSize, 1, 1);

			// Create the array for the data values
			amplitudeArray = new Uint8Array(analyserNode.frequencyBinCount);

			// setup the event handler that is triggered every time enough samples have been collected
			// trigger the audio analysis and draw one column in the display based on the results
			javascriptNode.onaudioprocess = function () {

				amplitudeArray = new Uint8Array(analyserNode.frequencyBinCount);
				analyserNode.getByteTimeDomainData(amplitudeArray);

				// draw one column of the display
				requestAnimFrame(drawTimeDomain);
			}

			// Now connect the nodes together
			// Do not connect source node to destination - to avoid feedback
			sourceNode.connect(analyserNode);
			analyserNode.connect(javascriptNode);
			javascriptNode.connect(audioContext.destination);
			
		}
		
		//Error function
		function error(){
			alert('Stream generation failed');
		}
		
		//draw animation on canvas element
		function drawTimeDomain() {
			clearCanvas();
			for (var i = 0; i < amplitudeArray.length; i++) {
				var value = amplitudeArray[i] / 256;
				var y = canvasHeight - (canvasHeight * value) - 1;
				ctx.fillStyle = '#ffffff';
				ctx.fillRect(i, y, 1, 1);
			}
		}
 
		//Clear canvas function
		function clearCanvas() {
			ctx.clearRect(0, 0, canvasWidth, canvasHeight);
		}
		
	</script>
</body>